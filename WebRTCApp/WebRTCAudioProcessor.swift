//
//  WebRTCAudioProcessor.swift
//  WebRTCApp
//
//  Created by Madi Sharipov on 03.07.2025.
//

import Foundation
import AVFoundation
import WebRTC

class WebRTCAudioProcessor: ObservableObject {
    @Published var isProcessing = false
    @Published var noiseLevel: Float = 0.01
    @Published var logs: [String] = []
    
    private var audioEngine: AVAudioEngine?
    private var inputNode: AVAudioInputNode?
    private var outputNode: AVAudioOutputNode?
    private var audioFormat: AVAudioFormat?
    
    // WebRTC –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    private var audioProcessingModule: RTCAudioProcessingModule?
    private var audioConfig: RTCAudioConfig?
    
    init() {
        addLog("üéØ WebRTC Audio Processor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        addLog("üì¶ –ö–∞—Å—Ç–æ–º–Ω–∞—è —Å–±–æ—Ä–∫–∞ WebRTC M110 (218b56e)")
        addLog("üîß –ò–Ω–∂–µ–∫—Ü–∏—è —à—É–º–∞ –∞–∫—Ç–∏–≤–Ω–∞ –≤ AudioProcessingImpl")
        setupAudioSession()
    }
    
    private func setupAudioSession() {
        do {
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.allowBluetooth, .allowBluetoothA2DP])
            try audioSession.setActive(true)
            addLog("‚úÖ Audio Session –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        } catch {
            addLog("‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Audio Session: \(error.localizedDescription)")
        }
    }
    
    func startAudioProcessing() {
        guard !isProcessing else { return }
        
        addLog("üöÄ –ó–∞–ø—É—Å–∫ WebRTC –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
        
        do {
            // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WebRTC Audio Processing Module
            audioConfig = RTCAudioConfig(
                sampleRate: 48000,
                channels: 1,
                framesPerBuffer: 480
            )
            
            audioProcessingModule = RTCAudioProcessingModule(config: audioConfig!)
            addLog("üìù WebRTC Audio Processing Module –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
            // –ù–∞—Å—Ç—Ä–æ–π–∫–∞ AVAudioEngine
            audioEngine = AVAudioEngine()
            inputNode = audioEngine?.inputNode
            outputNode = audioEngine?.outputNode
            
            guard let inputNode = inputNode,
                  let outputNode = outputNode,
                  let audioEngine = audioEngine else {
                addLog("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ AVAudioEngine")
                return
            }
            
            // –ü–æ–ª—É—á–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –∞—É–¥–∏–æ
            audioFormat = inputNode.outputFormat(forBus: 0)
            addLog("üéµ –ê—É–¥–∏–æ —Ñ–æ—Ä–º–∞—Ç: \(audioFormat?.description ?? "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")")
            
            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Ö–æ–¥—è—â–µ–≥–æ –∞—É–¥–∏–æ
            inputNode.installTap(onBus: 0, bufferSize: 1024, format: audioFormat) { [weak self] buffer, time in
                self?.processAudioBuffer(buffer)
            }
            
            // –ó–∞–ø—É—Å–∫–∞–µ–º –∞—É–¥–∏–æ –¥–≤–∏–∂–æ–∫
            try audioEngine.start()
            
            isProcessing = true
            addLog("‚úÖ WebRTC –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞")
            addLog("üîä –ò–Ω–∂–µ–∫—Ü–∏—è —à—É–º–∞ –∞–∫—Ç–∏–≤–Ω–∞ (—É—Ä–æ–≤–µ–Ω—å: \(String(format: "%.3f", noiseLevel)))")
            
        } catch {
            addLog("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: \(error.localizedDescription)")
        }
    }
    
    func stopAudioProcessing() {
        guard isProcessing else { return }
        
        addLog("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ WebRTC –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
        
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º AVAudioEngine
        audioEngine?.stop()
        inputNode?.removeTap(onBus: 0)
        
        // –û—á–∏—â–∞–µ–º WebRTC –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        audioProcessingModule = nil
        audioConfig = nil
        
        isProcessing = false
        addLog("‚úÖ WebRTC –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
    }
    
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let audioProcessingModule = audioProcessingModule,
              let audioFormat = audioFormat else { return }
        
        // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º AVAudioPCMBuffer –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è WebRTC
        let frameCount = Int(buffer.frameLength)
        let channelCount = Int(audioFormat.channelCount)
        
        // –°–æ–∑–¥–∞–µ–º –±—É—Ñ–µ—Ä—ã –¥–ª—è WebRTC
        var inputData: [[Float]] = Array(repeating: Array(repeating: 0.0, count: frameCount), count: channelCount)
        var outputData: [[Float]] = Array(repeating: Array(repeating: 0.0, count: frameCount), count: channelCount)
        
        // –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ AVAudioPCMBuffer
        if let floatChannelData = buffer.floatChannelData {
            for ch in 0..<channelCount {
                let channelData = floatChannelData[ch]
                for i in 0..<frameCount {
                    inputData[ch][i] = channelData[i]
                }
            }
        }
        
        // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ WebRTC (–∑–¥–µ—Å—å –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω –ø–∞—Ç—á —Å –∏–Ω–∂–µ–∫—Ü–∏–µ–π —à—É–º–∞)
        let result = audioProcessingModule.processStream(
            input: inputData,
            output: &outputData,
            sampleRate: Int32(audioFormat.sampleRate),
            channels: Int32(channelCount),
            frames: Int32(frameCount)
        )
        
        if result {
            addLog("üéõÔ∏è WebRTC –æ–±—Ä–∞–±–æ—Ç–∫–∞: —à—É–º –¥–æ–±–∞–≤–ª–µ–Ω –≤ \(frameCount) —Å—ç–º–ø–ª–æ–≤")
            
            // –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ
            playProcessedAudio(outputData, format: audioFormat)
        }
    }
    
    private func playProcessedAudio(_ audioData: [[Float]], format: AVAudioFormat) {
        // –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
        // –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –µ–≥–æ –≤ –¥—Ä—É–≥–æ–π –ø–æ—Ç–æ–∫
    }
    
    func setNoiseLevel(_ level: Float) {
        noiseLevel = level
        addLog("üéõÔ∏è –£—Ä–æ–≤–µ–Ω—å —à—É–º–∞ –æ–±–Ω–æ–≤–ª–µ–Ω –¥–æ: \(String(format: "%.3f", level))")
        addLog("üìä WebRTC AudioProcessingImpl –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å")
        
        // –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é WebRTC –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if let audioProcessingModule = audioProcessingModule {
            audioProcessingModule.setNoiseLevel(level)
            addLog("‚úÖ WebRTC –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞")
        }
    }
    
    func addLog(_ message: String) {
        DispatchQueue.main.async {
            let timestamp = DateFormatter.localizedString(from: Date(), dateStyle: .none, timeStyle: .medium)
            self.logs.append("[\(timestamp)] \(message)")
            
            // Keep only last 50 logs
            if self.logs.count > 50 {
                self.logs.removeFirst()
            }
        }
    }
}

// MARK: - WebRTC Wrapper Classes

class RTCAudioConfig {
    let sampleRate: Int32
    let channels: Int32
    let framesPerBuffer: Int32
    
    init(sampleRate: Int32, channels: Int32, framesPerBuffer: Int32) {
        self.sampleRate = sampleRate
        self.channels = channels
        self.framesPerBuffer = framesPerBuffer
    }
}

class RTCAudioProcessingModule {
    private var config: RTCAudioConfig
    private var noiseLevel: Float = 0.01
    
    init(config: RTCAudioConfig) {
        self.config = config
    }
    
    func processStream(input: [[Float]], output: inout [[Float]], sampleRate: Int32, channels: Int32, frames: Int32) -> Bool {
        // –ó–¥–µ—Å—å –±—É–¥–µ—Ç –≤—ã–∑–æ–≤ –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ WebRTC –∫–æ–¥–∞
        // –°–µ–π—á–∞—Å —Å–∏–º—É–ª–∏—Ä—É–µ–º —Ä–∞–±–æ—Ç—É –ø–∞—Ç—á–∞
        
        // –ö–æ–ø–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –≤—ã—Ö–æ–¥–Ω—ã–µ
        for ch in 0..<Int(channels) {
            for i in 0..<Int(frames) {
                output[ch][i] = input[ch][i]
            }
        }
        
        // –°–∏–º—É–ª–∏—Ä—É–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞ (–∫–∞–∫ –≤ –ø–∞—Ç—á–µ)
        let noiseIntensity = noiseLevel
        for ch in 0..<Int(channels) {
            for i in 0..<Int(frames) {
                let noise = Float.random(in: -noiseIntensity...noiseIntensity)
                output[ch][i] += noise
            }
        }
        
        return true
    }
    
    func setNoiseLevel(_ level: Float) {
        noiseLevel = level
    }
} 