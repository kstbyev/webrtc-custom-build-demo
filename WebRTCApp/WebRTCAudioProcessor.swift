//
//  WebRTCAudioProcessor.swift
//  WebRTCApp
//
//  Created by Madi Sharipov on 03.07.2025.
//

import Foundation
import AVFoundation
import WebRTC

class WebRTCAudioProcessor: ObservableObject {
    @Published var isProcessing = false
    @Published var noiseLevel: Float = 0.01
    @Published var logs: [String] = []
    
    private var audioEngine: AVAudioEngine?
    private var inputNode: AVAudioInputNode?
    private var outputNode: AVAudioOutputNode?
    private var audioFormat: AVAudioFormat?
    
    // WebRTC –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è - —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–∞—Ç–∏–≤–Ω—ã–µ –≤—ã–∑–æ–≤—ã
    private var webRTCProcessor: UnsafeMutableRawPointer?
    private let sampleRate: Int32 = 48000
    private let channels: Int32 = 2
    
    private var playerNode: AVAudioPlayerNode?
    private var audioBufferQueue = DispatchQueue(label: "audio.buffer.queue")
    
    init() {
        addLog("üéØ WebRTC Audio Processor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        addLog("üì¶ –ö–∞—Å—Ç–æ–º–Ω–∞—è —Å–±–æ—Ä–∫–∞ WebRTC M110 (218b56e)")
        addLog("üîß –ò–Ω–∂–µ–∫—Ü–∏—è —à—É–º–∞ –∞–∫—Ç–∏–≤–Ω–∞ –≤ AudioProcessingImpl")
        setupAudioSession()
        initializeWebRTC()
    }
    
    deinit {
        cleanupWebRTC()
    }
    
    private func setupAudioSession() {
        do {
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.allowBluetooth, .allowBluetoothA2DP])
            try audioSession.setActive(true)
            addLog("‚úÖ Audio Session –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            addLog("üé§ AVAudioSession –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω: \(audioSession.isOtherAudioPlaying ? "–µ—Å—Ç—å –¥—Ä—É–≥–æ–π –∑–≤—É–∫" : "–Ω–µ—Ç –¥—Ä—É–≥–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")")
        } catch {
            addLog("‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Audio Session: \(error.localizedDescription)")
        }
    }
    
    func startAudioProcessing() {
        guard !isProcessing else { return }
        addLog("üöÄ –ó–∞–ø—É—Å–∫ WebRTC –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
        guard webRTCProcessor != nil else {
            addLog("‚ùå WebRTC –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return
        }
        do {
            audioEngine = AVAudioEngine()
            inputNode = audioEngine?.inputNode
            outputNode = audioEngine?.outputNode
            guard let inputNode = inputNode,
                  let outputNode = outputNode,
                  let audioEngine = audioEngine else {
                addLog("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ AVAudioEngine")
                return
            }
            audioFormat = inputNode.outputFormat(forBus: 0)
            addLog("üéµ –ê—É–¥–∏–æ —Ñ–æ—Ä–º–∞—Ç: \(audioFormat?.description ?? "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")")
            // –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä—è–º–æ–π –≤—ã–≤–æ–¥ inputNode –Ω–∞ outputNode
            audioEngine.disconnectNodeOutput(inputNode)
            // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º playerNode
            playerNode = AVAudioPlayerNode()
            audioEngine.attach(playerNode!)
            if let format = audioFormat {
                audioEngine.connect(playerNode!, to: outputNode, format: format)
            }
            inputNode.installTap(onBus: 0, bufferSize: 1024, format: audioFormat) { [weak self] buffer, time in
                self?.processAudioBuffer(buffer)
            }
            try audioEngine.start()
            DispatchQueue.main.async {
                self.isProcessing = true
            }
            addLog("‚úÖ WebRTC –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞")
            addLog("üîä –ò–Ω–∂–µ–∫—Ü–∏—è —à—É–º–∞ –∞–∫—Ç–∏–≤–Ω–∞ (—É—Ä–æ–≤–µ–Ω—å: \(String(format: "%.3f", noiseLevel)))")
        } catch {
            addLog("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: \(error.localizedDescription)")
        }
    }
    
    func stopAudioProcessing() {
        guard isProcessing else { return }
        addLog("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ WebRTC –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
        audioEngine?.stop()
        inputNode?.removeTap(onBus: 0)
        playerNode?.stop()
        playerNode = nil
        audioEngine = nil
        inputNode = nil
        outputNode = nil
        audioFormat = nil
        DispatchQueue.main.async {
            self.isProcessing = false
        }
        addLog("‚úÖ WebRTC –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
    }
    
    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {
        guard let webRTCProcessor = webRTCProcessor,
              let audioFormat = audioFormat else { return }
        let frameCount = Int(buffer.frameLength)
        let channelCount = Int(audioFormat.channelCount)
        addLog("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ–±—É—Ñ–µ—Ä–∞: \(frameCount) —Å—ç–º–ø–ª–æ–≤, \(channelCount) –∫–∞–Ω–∞–ª–æ–≤")
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º ContiguousArray –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ—Å—Ç–∏ –ø–∞–º—è—Ç–∏
        var inputData: [ContiguousArray<Float>] = Array(repeating: ContiguousArray(repeating: 0.0, count: frameCount), count: channelCount)
        var outputData: [ContiguousArray<Float>] = Array(repeating: ContiguousArray(repeating: 0.0, count: frameCount), count: channelCount)
        if let floatChannelData = buffer.floatChannelData {
            for ch in 0..<channelCount {
                let channelData = floatChannelData[ch]
                for i in 0..<frameCount {
                    inputData[ch][i] = channelData[i]
                }
            }
        }
        let result = processAudioWithWebRTC(
            processor: webRTCProcessor,
            input: inputData,
            output: &outputData,
            frames: Int32(frameCount),
            noiseLevel: noiseLevel
        )
        // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ [[Float]] –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        let outputFloatData: [[Float]] = outputData.map { Array($0) }
        if result > 0 {
            addLog("üéõÔ∏è WebRTC –æ–±—Ä–∞–±–æ—Ç–∫–∞: —à—É–º –¥–æ–±–∞–≤–ª–µ–Ω –≤ \(frameCount) —Å—ç–º–ø–ª–æ–≤")
            playProcessedAudio(outputFloatData, format: audioFormat)
        }
        addLog("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ–±—É—Ñ–µ—Ä–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    }
    
    private func playProcessedAudio(_ audioData: [[Float]], format: AVAudioFormat) {
        addLog("‚ñ∂Ô∏è playProcessedAudio –≤—ã–∑–≤–∞–Ω, samples: \(audioData.first?.count ?? 0), channels: \(audioData.count)")
        let flat = audioData.flatMap { $0 }
        let minVal = flat.min() ?? 0
        let maxVal = flat.max() ?? 0
        addLog("üîä –ë—É—Ñ–µ—Ä –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è: min=\(minVal), max=\(maxVal)")
        guard let playerNode = playerNode else { return }
        let frameCount = AVAudioFrameCount(audioData[0].count)
        let channelCount = audioData.count
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameCount) else { return }
        buffer.frameLength = frameCount
        for ch in 0..<channelCount {
            if let channelData = buffer.floatChannelData?[ch] {
                for i in 0..<Int(frameCount) {
                    channelData[i] = audioData[ch][i]
                }
            }
        }
        audioBufferQueue.async {
            playerNode.scheduleBuffer(buffer, completionHandler: nil)
            if !playerNode.isPlaying {
                playerNode.play()
                self.addLog("‚ñ∂Ô∏è playerNode.play() –≤—ã–∑–≤–∞–Ω")
            }
        }
    }
    
    func setNoiseLevel(_ level: Float) {
        noiseLevel = level
        addLog("üéõÔ∏è –£—Ä–æ–≤–µ–Ω—å —à—É–º–∞ –æ–±–Ω–æ–≤–ª–µ–Ω –¥–æ: \(String(format: "%.3f", level))")
        addLog("üìä WebRTC AudioProcessingImpl –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å")
        
        // –û–±–Ω–æ–≤–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —à—É–º–∞ –≤ –Ω–∞—Ç–∏–≤–Ω–æ–º WebRTC –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ
        if let webRTCProcessor = webRTCProcessor {
            setNoiseLevelNative(processor: webRTCProcessor, level: level)
            addLog("‚úÖ WebRTC –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞")
        }
    }
    
    func addLog(_ message: String) {
        DispatchQueue.main.async {
            let timestamp = DateFormatter.localizedString(from: Date(), dateStyle: .none, timeStyle: .medium)
            self.logs.append("[\(timestamp)] \(message)")
            
            // Keep only last 50 logs
            if self.logs.count > 50 {
                self.logs.removeFirst()
            }
        }
    }
    
    // MARK: - WebRTC Native Integration
    
    private func initializeWebRTC() {
        addLog("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ WebRTC –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞...")
        
        // –°–æ–∑–¥–∞–µ–º –Ω–∞—Ç–∏–≤–Ω—ã–π WebRTC –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        webRTCProcessor = createAudioProcessor(sampleRate, channels)
        
        if webRTCProcessor != nil {
            addLog("‚úÖ –ù–∞—Ç–∏–≤–Ω—ã–π WebRTC –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            addLog("üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: \(sampleRate)Hz, \(channels) –∫–∞–Ω–∞–ª–æ–≤")
        } else {
            addLog("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞—Ç–∏–≤–Ω–æ–≥–æ WebRTC –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞")
        }
    }
    
    private func cleanupWebRTC() {
        if let processor = webRTCProcessor {
            destroyAudioProcessor(processor)
            webRTCProcessor = nil
            addLog("üßπ WebRTC –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –æ—á–∏—â–µ–Ω")
        }
    }
    
    private func processAudioWithWebRTC(
        processor: UnsafeMutableRawPointer,
        input: [ContiguousArray<Float>],
        output: inout [ContiguousArray<Float>],
        frames: Int32,
        noiseLevel: Float
    ) -> Int {
        var inputPointers: [UnsafePointer<Float>?] = input.map { $0.withUnsafeBufferPointer { $0.baseAddress } }
        var outputPointers: [UnsafeMutablePointer<Float>?] = []
        for i in 0..<output.count {
            outputPointers.append(output[i].withUnsafeMutableBufferPointer { $0.baseAddress })
        }
        assert(inputPointers.allSatisfy { $0 != nil }, "inputPointers contains nil")
        assert(outputPointers.allSatisfy { $0 != nil }, "outputPointers contains nil")
        let inputCArray = inputPointers.withUnsafeMutableBufferPointer { $0.baseAddress }
        let outputCArray = outputPointers.withUnsafeMutableBufferPointer { $0.baseAddress }
        return Int(processAudio(
            processor,
            inputCArray,
            outputCArray,
            frames,
            noiseLevel
        ))
    }
    
    private func setNoiseLevelNative(processor: UnsafeMutableRawPointer, level: Float) {
        setNoiseLevelNative(processor: processor, level: level)
    }
}

// MARK: - WebRTC Native Functions (imported from C++)

// –≠—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è –∏–∑ WebRTCWrapper.cpp —á–µ—Ä–µ–∑ bridging header
// –û–Ω–∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –ø—Ä—è–º—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å –Ω–∞—Ç–∏–≤–Ω—ã–º WebRTC –∫–æ–¥–æ–º 